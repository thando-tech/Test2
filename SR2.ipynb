{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8a7ec4-2c97-4226-8257-3c17adcd4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HOUSE_PIC</th>\n",
       "      <th>INTERVIEW_LANG</th>\n",
       "      <th>EDU_RECIEVED</th>\n",
       "      <th>INFO_RECIEVING</th>\n",
       "      <th>COMMUNICATION_WAY</th>\n",
       "      <th>LEADER_PARTICIPATION</th>\n",
       "      <th>COMMU_ORG</th>\n",
       "      <th>AVG_MON_SAL</th>\n",
       "      <th>HOUSE_HEAD</th>\n",
       "      <th>...</th>\n",
       "      <th>EDU_LEVEL</th>\n",
       "      <th>PARTICIPANT_JOB</th>\n",
       "      <th>SELF_BUILT_HOUSE</th>\n",
       "      <th>VEGES</th>\n",
       "      <th>FLOOD_EXP</th>\n",
       "      <th>YRLY_FLOOD</th>\n",
       "      <th>FIRE_EXP</th>\n",
       "      <th>WATER_SATISFIED</th>\n",
       "      <th>TOILET_TYPE</th>\n",
       "      <th>WATER_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-11T12:24:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word of mouth</td>\n",
       "      <td>Word of mouth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mother</td>\n",
       "      <td>...</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-11T12:24:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-11T12:24:20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social events</td>\n",
       "      <td>Mobile phone</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Wage employee</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Communal pit latrine</td>\n",
       "      <td>Community tap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-11T12:24:21</td>\n",
       "      <td>Yes</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>No</td>\n",
       "      <td>Lns</td>\n",
       "      <td>1000</td>\n",
       "      <td>Father</td>\n",
       "      <td>...</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Wage employee</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Communal pit latrine</td>\n",
       "      <td>Community tap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-11T12:24:21</td>\n",
       "      <td>Yes</td>\n",
       "      <td>zu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radio</td>\n",
       "      <td>Radio</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;500</td>\n",
       "      <td>Husband</td>\n",
       "      <td>...</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Communal pit latrine</td>\n",
       "      <td>Community tap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_TIME HOUSE_PIC INTERVIEW_LANG EDU_RECIEVED INFO_RECIEVING   \\\n",
       "0  2022-10-11T12:24:20       NaN             en          NaN   Word of mouth   \n",
       "1  2022-10-11T12:24:20       NaN             zu          NaN             NaN   \n",
       "2  2022-10-11T12:24:20       Yes             en          NaN   Social events   \n",
       "3  2022-10-11T12:24:21       Yes             en          NaN              TV   \n",
       "4  2022-10-11T12:24:21       Yes             zu          NaN           Radio   \n",
       "\n",
       "  COMMUNICATION_WAY LEADER_PARTICIPATION COMMU_ORG AVG_MON_SAL HOUSE_HEAD  \\\n",
       "0     Word of mouth                  NaN       NaN         NaN     Mother   \n",
       "1               NaN                  NaN       NaN         NaN        NaN   \n",
       "2      Mobile phone                   No       NaN        3500      Other   \n",
       "3                TV                   No       Lns        1000     Father   \n",
       "4             Radio                   No       NaN        <500    Husband   \n",
       "\n",
       "   ...  EDU_LEVEL PARTICIPANT_JOB SELF_BUILT_HOUSE VEGES FLOOD_EXP YRLY_FLOOD  \\\n",
       "0  ...  Secondary      Unemployed              NaN   NaN       NaN        NaN   \n",
       "1  ...        NaN             NaN              NaN   NaN       NaN        NaN   \n",
       "2  ...  Secondary   Wage employee               No    No        No        NaN   \n",
       "3  ...  Secondary   Wage employee               No    No        No        NaN   \n",
       "4  ...  Secondary      Unemployed              Yes   Yes       Yes          1   \n",
       "\n",
       "  FIRE_EXP WATER_SATISFIED           TOILET_TYPE   WATER_SOURCE  \n",
       "0      NaN             NaN                   NaN            NaN  \n",
       "1      NaN             NaN                   NaN            NaN  \n",
       "2      Yes             Yes  Communal pit latrine  Community tap  \n",
       "3      Yes             Yes  Communal pit latrine  Community tap  \n",
       "4      Yes              No  Communal pit latrine  Community tap  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (4435, 23)\n",
      "\n",
      "Data types of each column:\n",
      "DATE_TIME               object\n",
      "HOUSE_PIC               object\n",
      "INTERVIEW_LANG          object\n",
      "EDU_RECIEVED            object\n",
      "INFO_RECIEVING          object\n",
      "COMMUNICATION_WAY       object\n",
      "LEADER_PARTICIPATION    object\n",
      "COMMU_ORG               object\n",
      "AVG_MON_SAL             object\n",
      "HOUSE_HEAD              object\n",
      "NO_HOUSEHOLD            object\n",
      "CHANG_ECO_SITUA         object\n",
      "ACC_STATUS              object\n",
      "EDU_LEVEL               object\n",
      "PARTICIPANT_JOB         object\n",
      "SELF_BUILT_HOUSE        object\n",
      "VEGES                   object\n",
      "FLOOD_EXP               object\n",
      "YRLY_FLOOD              object\n",
      "FIRE_EXP                object\n",
      "WATER_SATISFIED         object\n",
      "TOILET_TYPE             object\n",
      "WATER_SOURCE            object\n",
      "dtype: object\n",
      "\n",
      "Summary statistics of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HOUSE_PIC</th>\n",
       "      <th>INTERVIEW_LANG</th>\n",
       "      <th>EDU_RECIEVED</th>\n",
       "      <th>INFO_RECIEVING</th>\n",
       "      <th>COMMUNICATION_WAY</th>\n",
       "      <th>LEADER_PARTICIPATION</th>\n",
       "      <th>COMMU_ORG</th>\n",
       "      <th>AVG_MON_SAL</th>\n",
       "      <th>HOUSE_HEAD</th>\n",
       "      <th>...</th>\n",
       "      <th>EDU_LEVEL</th>\n",
       "      <th>PARTICIPANT_JOB</th>\n",
       "      <th>SELF_BUILT_HOUSE</th>\n",
       "      <th>VEGES</th>\n",
       "      <th>FLOOD_EXP</th>\n",
       "      <th>YRLY_FLOOD</th>\n",
       "      <th>FIRE_EXP</th>\n",
       "      <th>WATER_SATISFIED</th>\n",
       "      <th>TOILET_TYPE</th>\n",
       "      <th>WATER_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4434</td>\n",
       "      <td>304</td>\n",
       "      <td>199</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>189</td>\n",
       "      <td>108</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>175</td>\n",
       "      <td>170</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>84</td>\n",
       "      <td>158</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>311</td>\n",
       "      <td>126</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Who would you define as the head of your house...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>zu</td>\n",
       "      <td>There is none</td>\n",
       "      <td>Mobile phone</td>\n",
       "      <td>Mobile phone</td>\n",
       "      <td>No</td>\n",
       "      <td>There is none</td>\n",
       "      <td>&lt;500</td>\n",
       "      <td>Father</td>\n",
       "      <td>...</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Communal pit latrine</td>\n",
       "      <td>Community tap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>64</td>\n",
       "      <td>140</td>\n",
       "      <td>86</td>\n",
       "      <td>26</td>\n",
       "      <td>69</td>\n",
       "      <td>96</td>\n",
       "      <td>144</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>116</td>\n",
       "      <td>77</td>\n",
       "      <td>87</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                DATE_TIME HOUSE_PIC  \\\n",
       "count                                                4434       304   \n",
       "unique                                                311       126   \n",
       "top     Who would you define as the head of your house...       Yes   \n",
       "freq                                                   64       140   \n",
       "\n",
       "       INTERVIEW_LANG   EDU_RECIEVED INFO_RECIEVING  COMMUNICATION_WAY  \\\n",
       "count             199             91             193               195   \n",
       "unique             36             56              17                17   \n",
       "top                zu  There is none    Mobile phone      Mobile phone   \n",
       "freq               86             26              69                96   \n",
       "\n",
       "       LEADER_PARTICIPATION      COMMU_ORG AVG_MON_SAL HOUSE_HEAD  ...  \\\n",
       "count                   189            108         164        166  ...   \n",
       "unique                   10             28          12         15  ...   \n",
       "top                      No  There is none        <500     Father  ...   \n",
       "freq                    144             24          57         69  ...   \n",
       "\n",
       "        EDU_LEVEL PARTICIPANT_JOB SELF_BUILT_HOUSE VEGES FLOOD_EXP YRLY_FLOOD  \\\n",
       "count         160             175              170   159       159         84   \n",
       "unique          6              15               12     3         3         15   \n",
       "top     Secondary      Unemployed               No    No       Yes          2   \n",
       "freq          119              89               93   143        87         29   \n",
       "\n",
       "       FIRE_EXP WATER_SATISFIED           TOILET_TYPE   WATER_SOURCE  \n",
       "count       158             127                   121            158  \n",
       "unique        3               2                     4              3  \n",
       "top         Yes             Yes  Communal pit latrine  Community tap  \n",
       "freq        116              77                    87            156  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\THANDOLWETHU\\Closed Ended Data.csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\THANDOLWETHU\\Closed Ended Data.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "\n",
    "# Display the data types of each column\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "display(df.describe(include='all'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1225f9d1-6f89-4f86-bfe8-fa68b17e3f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data in each column:\n",
      "DATE_TIME                  1\n",
      "HOUSE_PIC               4131\n",
      "INTERVIEW_LANG          4236\n",
      "EDU_RECIEVED            4344\n",
      "INFO_RECIEVING          4242\n",
      "COMMUNICATION_WAY       4240\n",
      "LEADER_PARTICIPATION    4246\n",
      "COMMU_ORG               4327\n",
      "AVG_MON_SAL             4271\n",
      "HOUSE_HEAD              4269\n",
      "NO_HOUSEHOLD            4263\n",
      "CHANG_ECO_SITUA         4269\n",
      "ACC_STATUS              4276\n",
      "EDU_LEVEL               4275\n",
      "PARTICIPANT_JOB         4260\n",
      "SELF_BUILT_HOUSE        4265\n",
      "VEGES                   4276\n",
      "FLOOD_EXP               4276\n",
      "YRLY_FLOOD              4351\n",
      "FIRE_EXP                4277\n",
      "WATER_SATISFIED         4308\n",
      "TOILET_TYPE             4314\n",
      "WATER_SOURCE            4277\n",
      "dtype: int64\n",
      "\n",
      "Columns with missing data:\n",
      "DATE_TIME                  1\n",
      "HOUSE_PIC               4131\n",
      "INTERVIEW_LANG          4236\n",
      "EDU_RECIEVED            4344\n",
      "INFO_RECIEVING          4242\n",
      "COMMUNICATION_WAY       4240\n",
      "LEADER_PARTICIPATION    4246\n",
      "COMMU_ORG               4327\n",
      "AVG_MON_SAL             4271\n",
      "HOUSE_HEAD              4269\n",
      "NO_HOUSEHOLD            4263\n",
      "CHANG_ECO_SITUA         4269\n",
      "ACC_STATUS              4276\n",
      "EDU_LEVEL               4275\n",
      "PARTICIPANT_JOB         4260\n",
      "SELF_BUILT_HOUSE        4265\n",
      "VEGES                   4276\n",
      "FLOOD_EXP               4276\n",
      "YRLY_FLOOD              4351\n",
      "FIRE_EXP                4277\n",
      "WATER_SATISFIED         4308\n",
      "TOILET_TYPE             4314\n",
      "WATER_SOURCE            4277\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"\\nMissing data in each column:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Display columns with missing data\n",
    "columns_with_missing_data = missing_data[missing_data > 0]\n",
    "print(\"\\nColumns with missing data:\")\n",
    "print(columns_with_missing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d77e98-1fcd-4e67-89b1-b9519b9d637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns in the dataset:\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(YRLY_FLOOD)\n\u001b[0;32m     10\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 11\u001b[0m df[YRLY_FLOOD] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[YRLY_FLOOD])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst few rows after normalization:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    467\u001b[0m     X,\n\u001b[0;32m    468\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[0;32m    469\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    470\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    471\u001b[0m )\n\u001b[0;32m    473\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "YRLY_FLOOD = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "print(\"\\nNumeric columns in the dataset:\")\n",
    "print(YRLY_FLOOD)\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[YRLY_FLOOD] = scaler.fit_transform(df[YRLY_FLOOD])\n",
    "\n",
    "print(\"\\nFirst few rows after normalization:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d606cc5-c749-49c0-aedb-485377c6092f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10526eae-3bf8-4f6c-8da7-a16a9410f1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f19a0-0ec2-4ab9-8656-97c6f56e54be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce47c4-00ed-416c-a6cc-16f971342a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
